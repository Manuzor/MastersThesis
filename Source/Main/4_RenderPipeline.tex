%!TEX root = ../Main.tex

\chapter{Vulkan Rendering}
\label{cha:RenderPipeline}
  \todo[inline]
  {
    Possible titles:
    Rendering Workflow,
    Applying the Rendering Pipeline,
    Rendering in Vulkan,
    Rendering Commands and Resource Handling/Management,
    Rendering Walkthrough/Guide,
    Specific/Concrete Example of a Rendering Pipeline
  }

  \todo[inline]{Image tiling and layout}
  \todo[inline]{Resource transformations.}

  This chapter provides an overview of the steps required to render an image using the Vulkan graphics \gls{api}.
  Because there are many ways to perform rendering with Vulkan, a framework is defined that constrains the actual work that needs to be done to a comprehensible amount.

  First, the aforementioned framework is defined.
  Subsequently, the necessary Vulkan \gls{api} calls are show and explained in order to prepare for rendering.
  Following these preparations, recording of the actual rendering commands is shown.
  And finally, in the render loop.
  Section~\ref{sec:MultithreadedRendering} at the end of this chapter provides additional information about multi-threaded rendering in Vulkan.

  Throughout this chapter, listings are presented that show the usage of select Vulkan commands and data structures that are required for rendering.
  It must be noted, however, that these listings are simplified in order to improve legibility.

  \section{Framework}
  \label{sec:Framework}
    \todo{Make sure to explain that the image is created only in a single step.}A simple forward renderer is assumed which means that rendering is performed to an image that is presented as soon as possible.
    A camera is used to observe the scene.
    This camera is not fixed, i.e. it may change position or rotation over time.
    The rendered scene will contain a fixed number of objects.
    Each object has fixed geometry and is assigned a single texture as well as a position in an application-defined coordinate space.
    Simple shaders are used to render each object of the scene.
    No complicated lighting algorithms are used.
    In fact, only flat shaded surfaces are produced.
    The actual layout of these shaders is discussed in section~\ref{subsubsec:VertexInputStateSetup}.

  \begin{figure}
    \includegraphics{Main/Images/RenderSetupAndLoopSimple}
    \centering
    \caption{Overview of the setup and execution of a simple forward-renderer in Vulkan as implemented in chapter~\ref{cha:RenderPipeline}.}
    \label{fig:RenderSetupAndLoopSimple}
  \end{figure}

  Figure~\ref{fig:RenderSetupAndLoopSimple} provides an abstract overview of this framework.
  The different steps depicted are explained during the course of this chapter.


  \section{Setup}
  \label{sec:RenderingSetup}
    Before it is possible to start rendering an image, proper Vulkan facilities need to be set up.
    \todo{Complete the sentence.}These are discussed in section.
    The setup here adheres to the framework defined in section~\ref{sec:Framework}.

    \subsection{Device and Queue Setup}
      \todo[inline]{Listings for this section?}
      The Vulkan device to be used for rendering needs to support both the swapchain extension as well as queues with graphics and present capabilities.

      In order for a rendered image to be presented to a window, the swapchain extension\footnote{Full name: \lstinline{VK_KHR_swapchain}} needs to be activated.
      This can be done when creating the device.
      Without this extension, no swapchain can be created for this device, which is necessary to present a rendered image in Vulkan.
      Note, however, that the swapchain is not created at this point.
      This has to be done explicitly by the application and is explained later.

      In Vulkan, rendering commands are submitted to a device queue.
      For the purposes of this chapter, queues with two specific capabilities are required.
      These capabilities are called the \textit{graphics capability} and the \textit{present capability}.
      The first specifies whether the queue supports graphics commands such as \lstinline{vkCmdDraw}\todo{Is it important \textbf{how} to get the info about the capabilities? Might be too much detail.}.
      The second capability specifies whether \lstinline{vkQueuePresentKHR} is supported on that queue.
      Without both of these capabilities, rendering and presenting an image is not possible.
      A queue might support both of these capabilities but it is also possible that two separate queues are used for graphics and presenting, respectively\todo{Rephrase?}.
      Once proper queues have been chosen, a logical device can be created.
      This logical device will be used for all subsequent Vulkan operations.
      The queues that were created along with the logical device will be used to submit rendering commands to the \gls{gpu} and to trigger the presentation engine.

    \subsection{Creating a Surface and a Swapchain}
      Now that a device with the enabled swapchain extension is in place, a swapchain can actually be created.
      Creating a swapchain requires what is called a Vulkan \textit{surface} to be created first.
      This surface is specific to the operating system and represents the connection to the actual window.
      It is also the target of the presentation engine, i.e. that surface is used to present a rendered image.

      \todo[inline]{Number, format, extent, colorspace of swapchain images.}
      \todo[inline]{Present modes / VSync.}
      A swapchain consists of multiple images.
      These images are managed by the presentation engine.
      The application may require the swapchain to create a certain number of images constrained to a range defined by the surface.

      \todo[inline]{Move this either to chapter 2 or 3. In this chapter, we mainly care about setting up the swapchain for the framework defined above.}
      The reason why an application may care about the number of swapchain images is rather straight-forward.
      From the point of view of the presentation engine, a swapchain image passes several stages until it is presented eventually.
      Initially the image is free and can be acquired by the application.
      Once an application acquires the image it is considered to be in use by the application and no longer free.
      At some point, the application hands back the image to the presentation engine, requesting that image to be presented.
      \todo{Explain more presentation modes?}In the \gls{fifo} presentation mode, the image will be put into a queue to be processed by the presentation engine at a convenient time.
      Once that time has come, the image will actually be presented on the surface.
      While an image is either currently presented or still pending presentation in the queue, it cannot be acquired by the application for rendering.
      When there is no free swapchain image, and the application tries to acquire one, the application will be stalled until a swapchain image is available.
      Depending on the chosen presentation mode, the number of swapchain images can be tuned to find the balance that works best for the application.
      Using too many swapchain images wastes memory but not having enough images may stall the application.

      Swapchain images will be used exclusively as color attachments for the framebuffer in this chapter.

    \subsection{Creating a Graphics Pipeline}
      \todo[inline]{Create framebuffer for each swapchain image, a render pass, and graphics pipeline. }
      \tbd

      \subsubsection{Shader Stage}
        \todo[inline]{Shader loading and module creation.}
        \todo[inline]{Only vertex and fragment shader in our case.}
        \tbd
        The graphics pipeline has one or more shader stages.
        Each shader stage needs to specify which pipeline a shader module

        \lstinputlisting[
          label=lst:ShaderStageSetup,
          caption={Setup of the shader stages for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=4,
          lastline=10,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

      \subsubsection{Vertex Input State}
        \label{subsubsec:VertexInputStateSetup}
        \tbd

        \lstinputlisting[
          label=lst:VertexInputStateSetup,
          caption={Vertex input state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=15,
          lastline=34,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

      \subsubsection{Input Assembly State}
        The input-assembly state describes how the input data to the vertex shader is interpreted.
        The most important parameter to set is the primitive topology.
        This is where the \gls{gpu} is told what kind of primitives the input data represents.
        For the purposes of this chapter, the chosen primitive topology is \lstinline{TRIANGLE_LIST}\footnote{Full name: \lstinline{VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST}}.

        \lstinputlisting[
          label=lst:InputAssemblyStateSetup,
          caption={Input assembly state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=39,
          lastline=40,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

      \subsubsection{Tessellation State}
        \todo[inline]{Just omit this state and subsubsection? It's nullptr in the graphics pipeline.}
        This state is only useful for the tessellation shader stage.
        In this chapter, only the vertex and fragment shader stages are in use so this state is ignored.

      \subsubsection{Viewport State}
        \label{subsubsec:ViewportState}
        The viewport state specifies how many viewports and scissors are active in a pipeline.
        Both the viewport and scissor define a non-rotated rectangular region within the framebuffer that will be written to by shaders.
        Rendering results that would usually write to the entire extent of the framebuffer will be scaled down and displaced to fit into the viewport and cropped to be inside the scissor.
        See figure~\ref{fig:ViewportScissorSample} for an illustration of this.
        In this chapter, only one of each is used that \todo{encompass?}include the entire framebuffer.

        \begin{figure}
          \includegraphics[width=0.8\textwidth]{Main/Images/ViewportScissorSample}
          \centering
          \caption{Framebuffer {\large$f_A$} has a viewport and scissor that contain the entire framebuffer. No transformation or cropping is performed. In framebuffer {\large$f_B$}, the viewport {\large$v$} causes the contents to be displaced and scaled down while scissor {\large$s$} causes the remaining contents to be cropped.}
          \label{fig:ViewportScissorSample}
        \end{figure}

        There are two ways to specify the actual viewport and scissor data.\todo{Explain briefly what viewport and scissors actually do.}{}
        The simplest way is to specify it at this point directly, \todo{Try reducing the use of i.e.}i.e. when creating the graphics pipeline.

        However, this also means that the viewport and scissor data may never change during the lifetime of the pipeline.
        Changing the viewport and scissor data is necessary when the dimension of the render targets change.
        For example, when the application window is resized, the swapchain along with all swapchain images typically need to be re-created with dimensions matching the new window size, thus the viewport and scissor need to be updated as well.

        \lstinputlisting[
          label=lst:DynamicStateSetup,
          caption={Dynamic state setup for viewport and scissor state in chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=45,
          lastline=51,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        \lstinputlisting[
          label=lst:ViewportStateSetup,
          caption={Viewport state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=53,
          lastline=55,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        In order to prevent re-creating the entire graphics pipeline every time, which is a costly operation, the pipeline can be configured to accept \textit{dynamic state} as shown in listing~\ref{lst:DynamicStateSetup}.
        Dynamic state has to be set everytime when a render pass is being processed.
        Dynamic state data is recorded in command buffers and submitted along with the relevant render pass commands.

        Because dynamic state for the viewport and scissor data is used in this chapter, specifying the number of viewports and scissors as shown in listing~\ref{lst:ViewportStateSetup} is sufficient for the purpose of setting up a graphics pipeline.

      \subsubsection{Rasterization State}
        The rasterization state is used to configure the behavior of the rasterizer.
        It can be configured to control how fragments are produced and the circumstances in which they may be discarded.

        It is also used to control how primitves are rasterized.
        For example, given a triangle primitve, there are three ways for the rasterizer to produce fragments: Densely fill the entire rectangle, only produce fragments for the outline of the triangle, or just produce a fragment for each of the vertices, respectively.

        The rasterizer can also be configured to perform face culling, i.e. discarding fragments that are facing in a certain direction.
        Without this option, fragments are produced regardless of the direction they are facing.
        However, it is common to enable back-face culling, i.e. discarding fragments that would be viewed from ``behind'', for triangle meshes that form a closed object.

        In order to perform culling, the rasterizer needs to know the facing direction of a triangle.
        This facing direction is also configurable in the rasterizer state.
        It is defined by the winding order of the vertices, which is considered to be either \textit{clockwise} or \textit{counter-clockwise}.

        \lstinputlisting[
          label=lst:RasterizationStateSetup,
          caption={Rasterization state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=60,
          lastline=62,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        % \todo[inline]{I don't show a listing for any of the other pipeline states. This is an experiment to see how it would be if I backed the text with corresponding listings.}

        In listing~\ref{lst:RasterizationStateSetup}, the rasterizer is configured to produce densely filled polygons and does not perform any culling operations on the fragments.

      \subsubsection{Multisample State}
        \label{subsubsec:MultisampleState}
        Multisampling is used to perform anti-aliasing, achieving a smoother appearance of jagged edges, and can be configured in the Multisample state.
        Disabling multisampling is not simply a matter of specifying the default value for all options.
        This state controls how many times the fragment shader is invoked and if a value of zero is passed as the number of samples, the fragment shader will never be invoked.

        Multisampling is not being used in this chapter so the number of samples is set to one.

        \lstinputlisting[
          label=lst:MultisampleStateSetup,
          caption={Multisample state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=67,
          lastline=68,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

      \subsubsection{Depth Stencil State}
        Depth and stencil tests are controlled in this state.
        Individual control is provided to enable depth testing, depth writing, depth bounds testing, as well as stencil testing.
        Depth bounds and comparison operations as well as stencil operations can be configured in this state.
        The comparison operation during depth tests can also be controlled.

        In this chapter, stencil tests are disabled.
        Depth testing, on the other hand, is enabled with depth bounds of $[0, 1]$ and with the typical less-or-equal comparison operation.

        \lstinputlisting[
          label=lst:DepthStencilStateSetup,
          caption={Depth and stencil state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=73,
          lastline=77,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

      \subsubsection{Color Blend State}
        The color blend state controls how color values produced by the fragment shader are combined, or blended, with the color that is already in the framebuffer.
        \todo{Mention `logicOp' and `blendConstants'?}
        The blend operations need to be specified for each render target individually.\todo{Mention that a pipeline is needed for each material.}{}
        Blend operations may also be turned off which simply replaces whatever was in the framebuffer with the output of the fragment shader.

        In addition to controlling blending, a color mask can be set that controls which components of the resulting color values are written to the framebuffer.
        If a color mask of 0 is supplied, the framebuffer contents will remain unchanged.
        Likewise, a color mask with all bits set to 1 will copy all color components to the framebuffer.
        It is crucial to set this value correctly, otherwise undesired behavior may be observed.

        \lstinputlisting[
          label=lst:ColorBlendStateSetup,
          caption={Color blend state setup for chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=82,
          lastline=88,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        In this chapter, blending is turned off and a color mask is chosen so all color components are copied to the framebuffer.

        \todo[inline]{Give an example (transparent vs. non-transparent) if there is enough time.}

      \subsubsection{Render Pass}
        \label{subsubsec:RenderPassSetup}
        Each graphics pipeline has exactly one render pass in Vulkan.
        A render pass consists of multiple subpasses and stores information about the flow of data between subpasses and the execution of rendering commands.
        It stores framebuffer attachment and information about layout transitions at the beginning and the end of the render pass as well as between subpasses.
        Framebuffer attachments are images such as a swapchain image or a depth-buffer.
        Each of these subpasses may reference the aforementioned framebuffer attachments of the render pass.
        Dependencies of each subpass are also stored in the render pass.
        Rendering commands are always recorded to one of the subpasses of a render pass \textit{instance}.
        Command buffer recording is discussed in section~\ref{sec:BuildCommandBuffers}.

        \todo[inline]{Give an example about subpasses (post-processing) if there is enough time.}

        \lstinputlisting[
          label=lst:RenderPassAttachmentsSetup,
          caption={Setup of the attachments for the render pass used in chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=93,
          lastline=106,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        In listing~\ref{lst:RenderPassAttachmentsSetup}, the attachments for the render pass are being set up.
        The first attachment, attachment 0, is the render target which is actually a swapchain image.
        The format of that attachment is set to the same format as the surface.
        Like before in section~\ref{subsubsec:MultisampleState}, the sampling count is set to 1, i.e. multisampling is not used.
        On line~4, the render pass is configured to clear the contents of the first attachment at load-time.
        The value to clear the contents with is defined in the render pass instance.
        Once the render pass has finished executing, the \lstinline{storeOp} determines what happens to this attachment.
        In this case, on line~5, the framebuffer contents are preserved.
        Alternatively, the render pass can be configured to discard the results instead but that is not the desired behavior in this particular case.

        The subsequent settings are used to control the image layout at the beginning and the end of a render pass, respectively.
        On line~6, the initial layout of the attachment is specified to be undefined.
        This tells the \gls{driver} that it may discard the contents if it sees fit.
        The previous contents of the attachment are not relevant for this render pass because the attachment is cleared as the first operation when loaded by this render pass.
        On line~7, the render pass is configured to ensure that the image layout state of the attachment is \lstinline{PRESENT_SRC}\footnote{Full name: \lstinline{VK_IMAGE_LAYOUT_PRESENT_SRC_KHR}}.
        This way no further transformations to the undrelying swapchain image have to be performed before it can be presented.

        On lines 9--14, the depth buffer attachment is configured.
        The format of this attachment is set to the format of the actual depth buffer.
        Similarly to the first attachment, the depth buffer is cleared at the beginning of the render pass.
        The \lstinline{storeOp} is set to \lstinline{DONT_CARE}\footnote{Full name: \lstinline{VK_ATTACHMENT_STORE_OP_DONT_CARE}} because the depth buffer is not used outside the render pass.
        This is also the reason why both the inital and the final layout are simply set to \lstinline{DEPTH_STENCIL_ATTACHMENT}\footnote{Full name: \lstinline{VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL}}.

        \lstinputlisting[
          label=lst:RenderPassSubpassSetup,
          caption={Setup of the single subpass for use in chapter~\ref{cha:RenderPipeline}.},
          style=MyCppFloat,
          firstline=108,
          lastline=120,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        As mentioned before, a render pass consists of multiple subpasses.
        Every render pass needs at least one subpass.
        For the purposes of this chapter, a single subpass is sufficient.
        This subpass is configured as shown in listing~\ref{lst:RenderPassSubpassSetup}.

        A subpass accepts configurations for the layout of individual attachments.
        Subpasses have references to the attachments of the render pass itself.
        These attachment references contain additional information, the most important one being the layout in that subpass.
        On line~2 of listing~\ref{lst:RenderPassSubpassSetup}, the index of the referenced attachment in the render pass is set.
        On line~3, the attachment reference is configured to ensure the correct image layout for the referenced attachment during the execution of that subpass.
        Every subpass within a render pass may define their own requirements for the layout of every individual attachment.
        Image layout transitions are performed by the \gls{driver} between subpasses as needed to ensure each subpass uses the attachment in the required layout.
        The depth-stencil reference on lines 6 and 7 is referencing the remaining attachment of the render pass and requires the \lstinline{DEPTH_STENCIL_ATTACHMENT} layout for this attachment.

        Note that the depth-stencil attachment reference on line~13 is only a single element, not an array.
        Color references on line~11 and 12, on the other hand, are not limited to a single instance.
        This means that a subpass may reference many color attachments but only a single depth-stencil attachment.

        \lstinputlisting[
          label=lst:RenderPassCreation,
          caption={Creation of a render pass object using the data defined in listings~\ref{lst:RenderPassAttachmentsSetup}~and~\ref{lst:RenderPassSubpassSetup}.},
          style=MyCppFloat,
          firstline=122,
          lastline=129,
          float
        ]
        {Main/Listings/GraphicsPipelineSetup.cpp}

        And finally, the attachment and subpass information defined previously are combined and passed to the appropriate Vulkan command on line~8 in listing~\ref{lst:RenderPassCreation} to create the actual render pass object.

    \subsection{Creating Scene Objects}
      \label{subsubsec:CreatingSceneObjects}
      \todo[inline]{Create renderable objects. Needs sampled image, geometry. Mention push constants.}
      \todo[inline]{Mention the transformation matrix being in a uniform buffer.}
      \tbd

  \section{Command Buffer Recording}
  \label{sec:BuildCommandBuffers}
    \todo[inline]{Command buffer submission. Mention out-of-order execution. Analogous to CPU instruction dispatch.}

    Rendering in Vulkan is done by issuing rendering commands.
    These commands are not dispatched to the \gls{gpu} directly but recorded into a \textit{command buffer} which is submitted to a device queue for execution.
    Command buffers have been introduced in chapter~\ref{cha:VulkanOverview}, specifically section~\ref{sec:CommandBuffers}.

    Command buffer objects are created using \textit{command pools}.
    Command pools manage the memory of the command buffers created from them.
    A command buffer is either in the \textit{initial}, \textit{recording}, or \textit{executable} state.
    The contents of a command buffer are immutable for as long as that command buffer is \textit{executable}.
    Resetting a command buffer clears its contents and reverts it to the \textit{initial} state.
    It must be noted that submitting a command buffer also does not clear its contents.
    This means that command buffers may be recorded once and executed multiple times.
    This can be very useful when recording a series of render commands for state .
    It also improves performance insofar that the \gls{driver} is able to keep frequently used command buffers in \gls{gpu} memory, reducing required communication overhead between the \gls{cpu} and the \gls{gpu} and thus, reducing required bandwidth for data transmission.
    An example for such kinds of command buffers is for rendering state scene geometry.
    This kind of geometry is does not change with time, hence the commands required for rendering also do not change.

    For the purposes of this chapter, command buffers will only be recorded once and submitted in the render loop in section~\ref{sec:RenderLoop}.
    The framework defined before allows this to be possible because all objects in the scene are static in terms of rendering commands.
    However, this is only true because per-object shader data is stored in uniform buffer objects as established in section~\ref{subsubsec:CreatingSceneObjects}.
    Uniform buffers are independent of the rendering commands and can be updated directly using memory mapping operations.
    Alternatively to uniform buffers, \textit{push constants} may be used to supply data to be used in shaders.
    Compared to uniform buffer objects, push constants have certain limitations that need to be considered.

    For each shader module, only a single \textit{push constant block} may be declared.
    The size of such a block is limited.
    The Vulkan specification requires that \glspl{driver} support sizes of at least 128 bytes but larger blocks may also be supported.
    The upper limit is specific to individual devices and can be queried using the Vulkan \gls{api}.
    Sizes of 256 bytes are common on current \gls{nvidia} hardware.
    Because of small sizes like this, push constants are likely to be stored in registers directly as opposed to uniform buffers which are stored in \gls{vram}.
    A note in section~13.2.6 also hints that using push constants may yield improved performance in terms of execution speed.

    The way values are supplied for push constant blocks is different from how a uniform buffer object is updated.
    Push constant values are updated using commands and are recorded to command buffers.
    This means that these values may be different for each recorded command buffer.
    If values are stored in the push constant block that change every frame, such as the model-view-projection matrix of a scene object, command buffers need to be recorded every frame.

    \subsection{Rendering a Scene Object}
      In this section, the necessary steps to record rendering commands for all scene objects are shown and explained.

      \lstinputlisting[
        label=lst:BeginCommandBuffer,
        caption={Start of the recording of a command buffer.},
        style=MyCppFloat,
        firstline=1,
        lastline=2,
        float
      ]
      {Main/Listings/CommandBufferRecording.cpp}

      % The first action that has to be performed is to start command buffer recording.
      Before issuing rendering commands, the command buffer has to be put into \textit{recording} state, which can be seen on line~2 of listing~\ref{lst:BeginCommandBuffer}.
      When beginning a command buffer, additional information can be passed in the \lstinline{VkCommandBufferBeginInfo} structure which can be seen on line~1.
      For example, this can be used to inform Vulkan that this particular command buffer is only submitted once which might allow the \gls{driver} to perform optimizations.
      For the purposes of this example, the default values are sufficient.

      \lstinputlisting[
        label=lst:DynamicStateUpdate,
        caption={Updating dynamic render pass state using Vulkan commands.},
        style=MyCppFloat,
        firstline=4,
        lastline=13,
        float,
        emph={vkCmdSetViewport, vkCmdSetScissor}
      ]
      {Main/Listings/CommandBufferRecording.cpp}

      Once the command buffer is \textit{recording}, the dynamic state can be set.
      As defined in section~\ref{subsubsec:ViewportState} and shown in listing~\ref{lst:DynamicStateSetup}, the dynamic state to update include the viewport and scissor.
      \todo{Highlight vkCmdSet* in the listings?}
      The commands for updating this state are shown in listing~\ref{lst:DynamicStateUpdate}.
      The viewport is set to include the entire framebuffer on lines~2--3 as well as the entire depth buffer extent on lines~4--5.
      The scissor is set to contain the entire viewport on line~9, effectively disabling cropping of the resulting image.

      Dynamic state values are part of the command buffer.
      These values are read by graphics pipelines when executing draw commands without clearing them.
      This means that dynamic state only has to be set once for every command buffer if the values never change which why dynamic state updates are the first commands recorded in the example of this chapter.
      These commands may be recorded at a later point if need be, but no later than before the first draw command is recorded.
      Additionally, setting these values is only necessary if the graphics pipeline has been set up to accept viewport and scissor data as dynamic state.
      Graphics pipelines that are not instructed to look for dynamic state will simply ignore the data in the command buffer and instead use the data supplied at pipeline creation.

      \lstinputlisting[
        label=lst:BeginRenderPass,
        caption={Creation of a render pass instance within a command buffer.},
        style=MyCppFloat,
        firstline=15,
        lastline=25,
        float,
        emph={vkCmdBeginRenderPass}
      ]
      {Main/Listings/CommandBufferRecording.cpp}

      In the next step, a render pass is started which results in the creation of a \textit{render pass instance}.
      This render pass instance is associated with a specific framebuffer on line~7 and clear values on line~10~and~11 that are used to clear attachment contents if their \lstinline{loadOp} is set to \lstinline{CLEAR}\footnote{Full name: \lstinline{VK_ATTACHMENT_LOAD_OP_CLEAR}}.
      The \lstinline{loadOp} settings were specified for each attachment in section~\ref{subsubsec:RenderPassSetup}.
      Another property of the render pass instance is the render area on line~8.
      As can be seen, it set to the same value as the scissor that was set before.
      The render area is used to control which pixels of the framebuffer are affected in the active render pass.
      This is used to minimize necessary work for the \gls{gpu}.
      As per the Vulkan specification, a render area that is smaller than the entire framebuffer may affect performance negatively.
      A render area that is larger than the framebuffer is invalid.

      When beginning a render pass, Vulkan also needs to be told about whether secondary command buffers will be used or not.
      For the purposes of this chapter, only a single primary command buffer is used in a single subpass, which is why the render pass is instructed to inline render commands directly in the primary command buffer, disallowing execution of secondary command buffer.\todo{Refer to where primary and secondary command buffers are explained.}{}

      \todo[inline]
      {
        If the reader is not following carefully, it might seem like scissors do the same thing as the render area, which is not strictly true.
        First, there may be many scissors but only a single render area at once.
        Secondly, scissors are specified as part of the pipeline while the render area is part of the render pass \textbf{instance}.
        Should I mention and explain this?
        It should be obvious from the text and would be redundant.
      }

      \lstinputlisting[
        label=lst:ObjectRenderingLoop,
        caption={Rendering of all scene objects.},
        style=MyCppFloat,
        firstline=27,
        lastline=40,
        float
      ]
      {Main/Listings/CommandBufferRecording.cpp}

      Now that a render pass instance is set up, draw commands can be recorded.
      Because there are multiple objects in the scene that need to be rendered, this will happen in a loop as can be seen on line~1 in listing~\ref{lst:ObjectRenderingLoop}.
      The first command causes the binding of a descriptor set with a specific pipeline layout.\todo{Reference where descriptor sets and pipeline layouts are first explained.}{}
      \todo{Explain the other, optional arguments?}

      \todo[inline]{Explain why the pipeline is bound later than the render pass. Maybe mention that a render pass may be shared between multiple pipelines.}
      Afterwards, the command to bind the graphics pipeline is recorded on line~9.
      It is explicitly stated that the passed pipeline object is a graphics pipeline.

      \todo{Too informal?}With a pipeline in place, the vertex buffer and index buffer objects are bound.
      In both cases, the entire buffers are used, which is why all offsets are set to zero.
      As can be seen on line~11, multiple vertex buffers can be bound at once.
      Vertex buffers may be bound to different binding locations using the second argument to the depicted Vulkan API call, as long as these locations are valid for the given pipeline layout.
      In the case of this example, only a single vertex buffer is used per object that is bound to location 0.
      The indices in the index buffer contains unsigned 32~bit integer values.
      This information is passed to Vulkan on line~12.

      Following all the binding commands, the actual drawing command is issued.
      There are several drawing commands available but for the combination of objects that are bound only indexed drawing is valid.
      Because rendering is supposed to be done by using the bound index buffer, the drawing command to be recorded is \lstinline{vkCmdDrawIndexed}.
      The arguments are, in order, the number of indices to read from the index buffer, the number of instances to render, the index of the index buffer to use, an offset that is added to each value in the index buffer before it is used to perform vertex lookups, and finally the ID of the first instance to draw.
      Because instanced rendering is not intended, the instance count is set to 1 and the ID of the first instance is set to 0.
      The index buffer is assumed to be set up to reference every vertex directly.
      This means that the entire index buffer can be used with both offsets set to 0 and the count set to the number of available indices in the index buffer.

      \lstinputlisting[
        label=lst:ConcludingCommandBufferRecording,
        caption={Completion of the render pass and command buffer recording.},
        style=MyCppFloat,
        firstline=42,
        lastline=43,
        float
      ]
      {Main/Listings/CommandBufferRecording.cpp}

      Once all commands have been recorded, the render pass and the command buffer may be ended.
      This is shown in listing~\ref{lst:ConcludingCommandBufferRecording}.
      This transitions the command buffer from \textit{recording} to \textit{executable} state.
      The function \lstinline{vkEndCommandBuffer}, as seen on line~2, returns a status code of type \lstinline{VkResult}.
      If an error occurred during command buffer recording, all subsequent \lstinline{vkCmd*} calls will be ignored and an error code will be return when the command buffer is ended.
      For example, the command buffer may run out of memory early on and signal this once recording has ended.

      The command buffer is now ready for submission to a queue and execution on the \gls{gpu}.
      This is covered in section~\ref{sec:RenderLoop}.\todo{More verbose conclusion paragraph? Or remove it?}{}


  \section{Rendering Loop}
  \label{sec:RenderLoop}
    \todo[inline]{Rather simple because of pre-recording command buffers.}
    \todo[inline]{Update shader data (UBOs, dynamic state, etc).}
    \todo[inline]{Possibly explain push constants.}
    \todo[inline]{Acquire swapchain image.}
    \todo[inline]{Submit command buffers.}
    \todo[inline]{Present swapchain image.}
    \todo[inline]{Sync for submission and presenting (render semaphore, present semaphore) so swapchain image isn't used for rendering while presenting and vice versa. Also image layout transition happens with commands, meaning sync is necessary!}
    \tbd

    \lipsum

    \lstinputlisting[
      label=lst:RenderLoop_SemaphoreCreation,
      caption={Creation of two semaphores used in the render loop.},
      style=MyCppFloat,
      firstline=1,
      lastline=3,
      float
    ]
    {Main/Listings/RenderLoop.cpp}

    \lipsum

    \lstinputlisting[
      label=lst:RenderLoop_ShaderDataUpload,
      caption={Creation of two semaphores used in the render loop.},
      style=MyCppFloat,
      firstline=5,
      lastline=19,
      float
    ]
    {Main/Listings/RenderLoop.cpp}

    \lipsum

    \lstinputlisting[
      label=lst:RenderLoop_AcquireNextImage,
      caption={Creation of two semaphores used in the render loop.},
      style=MyCppFloat,
      firstline=21,
      lastline=27,
      float
    ]
    {Main/Listings/RenderLoop.cpp}

    \lipsum

    \lstinputlisting[
      label=lst:RenderLoop_QueueSubmission,
      caption={Creation of two semaphores used in the render loop.},
      style=MyCppFloat,
      firstline=30,
      lastline=43,
      float
    ]
    {Main/Listings/RenderLoop.cpp}

    \todo[inline]{Next action is command buffer submission. Mention that it must be re-recorded here is push constants would be used.}

    \lipsum

    \lstinputlisting[
      label=lst:RenderLoop_QueuePresent,
      caption={Creation of two semaphores used in the render loop.},
      style=MyCppFloat,
      firstline=45,
      lastline=55,
      float
    ]
    {Main/Listings/RenderLoop.cpp}

    \lipsum

    \lstinputlisting[
      label=lst:RenderLoop_QueueWaitIdle,
      caption={Creation of two semaphores used in the render loop.},
      style=MyCppFloat,
      firstline=57,
      lastline=61,
      float
    ]
    {Main/Listings/RenderLoop.cpp}

    \lipsum

  \section{Window Resizing}
    \todo[inline]{Should I actually add this section? (Only if there's enough time.)}
    \tbd

  \section{Multi-threaded Rendering}
  \label{sec:MultithreadedRendering}
    \todo[inline]{Introduction to this chapter. Motivation. Additional complexity. Applications must be sure they gain anything from using multi-threading.}
    As mentioned in chapter~\ref{cha:VulkanOverview}, Vulkan API calls are not synchronized implicitly by the \gls{driver} in order to facilitate multi-threaded processing.
    However, this does not mean that multi-threading on the \gls{cpu} has not been taken into account when Vulkan was designed.
    There are actually several ways of utilizing multiple threads for rendering with Vulkan.
    Creating resources and recording command buffers from multiple threads are explored in the following subsections.

    \subsection{Multi-threaded Command Buffer Recording}
      A naive approach to utilize multi-threading is to create several command buffers and assign them to multiple threads.
      These threads would then record commands to their assigned command buffers and submit them to a device queue.
      Unfortunately, there are some problems with this approach.
      According to sections~5.3~and~5.4 of the Vulkan specification\cite{vkspec}, the host application is responsible for synchronizing interactions with command buffers and submitting them to device queues.

      % Problem with command buffers and multi-threaded access.
      Command buffer access is not thread-safe.
      This is because memory used by command buffers is managed by the parent command pool.
      The actual algorithms used for managing memory are left to the \gls{driver}.
      % Done for implementations to be more memory efficient.
      This allows command pools efficient handling of memory operations performed by multiple command buffers, e.g. by allocating more memory than is currently needed and reassigning it as more is requested.
      % Command buffers work on memory managed by parent command pool.
      Because command pools are free to manage memory as they see fit, any operation on a command buffer may trigger side-effects that affect other command buffers created from the same pool.
      This fact alone makes command buffers unsuitable to be shared across multiple threads without synchronization.

      % Command pools do not depend on anything else.
      Command pools, on the other hand, are independent objects.
      The memory they manage is only used for command buffers they created.
      Whenever available memory is no longer sufficient, new memory from the host is requested, optionally using a application-supplied allocator.
      This allocator needs to synchronize low-level allocations, like the C standard library function \lstinline{malloc} already does.
      % Thus solution is to assign each thread its own command pool.
      Synchronization of low-level memory allocation is certainly not as costly as synchronizing each command buffer access.
      Typically, those low-level memory allocations do not happen very often.
      It is likely that command pool implementations strive for minimal host allocations.

      Command pools effectively do not need to be manually synchronized across multiple threads if they are not shared between them.
      In addition, command buffers created from such command pools inherit the same properties.
      Thus, it is more suitable to assign one or more command pools per thread.
      % Threads then allocate and record into as many command buffers as needed.
      Each thread is then free to allocate and record into as many command buffers as needed without having to conduct fine-grained synchronization.

      % Let main thread submit command buffers by sharing a datastructure with synchronized access.
      In order for command buffers allocated on other threads to be submitted to the device queue, the main thread may provide a shared datastructure that is capable of containing command buffer objects.
      Access to this shared container would be synchronized using traditional synchronization methods.
      % Turns the initial problem into well-understood producer-consumer problem\cite{EWD:EWD329}.
      % Solves the inital queue submission problem.
      This effectively creates the well-understood producer-consumer scenario\cite{EWD:EWD329} and solves the initial queue submission problem.

      \todo[inline]{Prev paragraph is just a suggestion. May be better to do differently. Depends on application.}

      \subsubsection{Command Buffer Management Considerations}
        % ... There is another problem with the system mentioned above.
        % ... It is also recommended to assign more than one command pool to an individual thread.
        % ... While a command buffer is being processed, i.e. once it has been submitted but has not finished execution yet, the command buffer should not be modified.
        % ... The reason why multiple pools should be used instead of simply creating new command buffers from the same pool is because of the underlying memory model.

        % ... In the previously described scenario, each thread has exactly one command pool that is used to create multiple command buffers from.
        % ... Commands are recorded to these command buffers and are submitted in batches to the device for execution.
        % ... Vulkan specifies some restrictions on what may be done with command buffers that are pending execution.
        % ... For example, the application should not free a command buffer that is pending execution.

        % Command buffers need to be kept alive while pending execution.
        Vulkan prohibits modifying submitted command buffers that are pending execution on the device.
        This includes freeing these command buffers, i.e. the application is responsible for keeping them alive as long as they are pending execution.
        In practice, this effectively means command buffers submitted in batches may only be modified or reused once the entire submission has finished execution because it is hard to predict when individual commands are processed if more than one command buffer is submitted.
        Out-of-order execution is one reason for this unpredictability.
        The simplest way to solve this problem is to just use new command buffers for every new batch submission.
        This poses some management overhead since individual command buffers need to be associated to these batches in some way in order to be freed or reused.
        Vulkan does not do this automatically.
        Otherwise, if command buffers are never freed, the application ends up allocating a lot more than necessary, effectively leaking memory.

        % Command pools better than just using command buffers because of decoupled underlying memory and clean separation of concern.
        A better way might be to use command pools for this purpose.
        Managing command buffers is already what they do and it also offers a clean separation of concerns between the different batches of command buffers.
        In other words, using command pools to allocate command buffers that are submitted together provides a way to manage these command buffers using standard methods.
        Vulkan allows command pools to be reset, effectively resetting all command buffers spawned from them.
        This means that command pools may be reused after their associated batch of submitted command buffers has finished execution.
        When resetting a command pool, the host application is free to choose whether memory allocated by that command pool should be released or not.
        If a command pool is going to be reused, and the memory is not released, this command pool can directly start producing command buffers without causing additional allocation overhead.
        This provides a clean way for managing command buffer lifetimes without the need to use anything but the Vulkan \gls{api} itself.

        \todo{Describe what they did differently?}Similar approaches have been described by industry experts such as Marius Bjørge\cite{bjorge:multithreadingvulkan} in his blog post about multi-threading in Vulkan as well as Mathias Schott\cite{mschott:vulkan_multi_threading} in his talk entitled ``Vulkan multi-threading''.

        Care must be taken, however, in cases where the amount of memory required by a command buffer is not steady during its lifetime.
        For example, when transitioning from a large \gls{3d} scene, with many objects to render, to a small scene with less draw calls to perform, the memory requirements of each command buffer may be lowered considerably for the new scene.
        In cases like this, it might make sense to reset all relevant command buffers, freeing their associated memory.
        Switching from a small scene to larger one is not a problem, of course, because the command buffer will simply allocate enough memory for the new scene.


    \subsection{Multi-threaded Resource Creation}
      \todo[inline]{Mention staging buffers somehow?}
      Vulkan applications need to create resources such as images and shaders.
      Loading and creating these resources may take a considerable amount of time, depending on the data in question.
      Images, for example, can be quite large.
      They may also have to be transformed in some way which also consumes computation time.
      Shaders need to be compiled (by the \gls{driver}) and bound to a Vulkan pipeline.
      Many of these time consuming operations work more or less independently from the rest of the system, depending on the specific operation.
      This makes them interesting candidates for execution on multiple threads.
      However, the use of multi-threaded resource creation introduces additional complexity to the system.

      First of all, an application has to decide how many threads are actually needed for resource creation.
      It is possible that only one dedicated resource creation thread is sufficient for many applications.
      The actual number of resource creation threads depends on the application.

      All resource creation threads need device memory in one way or another.
      There are basically two ways of accomplishing this without race conditions.
      The first way is to preallocate the memory that is available for each thread.
      This method does not require synchronization between threads because each is assigned a memory region that is not overlapping memory from other threads.
      The second way is to assign a memory allocator to each thread that internally synchronizes the calls.
      This method does not require the main thread to know the size of the resources each thread creates but memory allocations need to be synchronized.
      Again, the method of choice depends on the application.
